---
date: 2017-07-11T00:00:00Z
draft: true
lang: en
tags: [ TODO_TAGS ]
title: TODO_TITLE
type: link # image quote video text audio chat
via: "[Who](http://example.com)"
---


2017-07-11 via Steve Smith
https://equalexperts.slack.com/archives/C03L7FXDH/p1499091320469195

A research paper on why complex systems fail:
http://web.mit.edu/2.75/resources/random/How%20Complex%20Systems%20Fail.pdf

> 1) Complex systems are intrinsically hazardous systems.
> 2) Complex systems are heavily and successfully defended against failure.
> 3) Catastrophe requires multiple failures – single point failures are not enough.
> 4) Complex systems contain changing mixtures of failures latent within them.
> 5) Complex systems run in degraded mode.
> 6) Catastrophe is always just around the corner.
> 7) Post-accident attribution accident to a ‘root cause’ is fundamentally wrong.
> 8) Hindsight biases post-accident assessments of human performance.
> 9) Human operators have dual roles: as producers & as defenders against failure.
> 10) All practitioner actions are gambles.
> 11) Actions at the sharp end resolve all ambiguity.
> 12) Human practitioners are the adaptable element of complex systems.
> 13) Human expertise in complex systems is constantly changing
> 14) Change introduces new forms of failure.
> 15) Views of ‘cause’ limit the effectiveness of defenses against future events. 
> 16) Safety is a characteristic of systems and not of their components
> 17) People continuously create safety. 
> 18) Failure free operations require experience with failure.

See also:
[https://www.youtube.com/watch?v=2S0k12uZR14](https://www.youtube.com/watch?v=2S0k12uZR14)

—//—

HF: temp summary link _http://www.itskeptic.org/great-paper-failure-complex-systems__
_

TODO: Also link to the it skeptic site?
